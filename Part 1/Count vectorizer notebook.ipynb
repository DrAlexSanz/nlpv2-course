{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Count Vectorizer demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "B1mucd5kiisR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
        "from nltk.corpus import wordnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\sanza\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\sanza\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     C:\\Users\\sanza\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download(\"wordnet\")\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"averaged_perceptron_tagger\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>High fuel prices hit BA's profits\\n\\nBritish A...</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Pernod takeover talk lifts Domecq\\n\\nShares in...</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text    labels\n",
              "0  Ad sales boost Time Warner profit\\n\\nQuarterly...  business\n",
              "1  Dollar gains on Greenspan speech\\n\\nThe dollar...  business\n",
              "2  Yukos unit buyer faces loan claim\\n\\nThe owner...  business\n",
              "3  High fuel prices hit BA's profits\\n\\nBritish A...  business\n",
              "4  Pernod takeover talk lifts Domecq\\n\\nShares in...  business"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# This a notebook we use as a baseline: https://www.kaggle.com/datasets/shivamkushwaha/bbc-full-text-document-classification\n",
        "df = pd.read_csv(\"bbc_text_cls.csv\")\n",
        "df.head() # Each row is a full article and the second column is a class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "inputs = df[\"text\"]\n",
        "labels = df[\"labels\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<AxesSubplot:>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "labels.hist(figsize = (10, 5)) # It's quite balanced"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train test split BEFORE the count vectorizer, I only count on train set\n",
        "\n",
        "inputs_train, inputs_test, y_train, y_test = train_test_split(inputs, labels, random_state = 123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Now count\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "x_train = vectorizer.fit_transform(inputs_train)\n",
        "x_test = vectorizer.transform(inputs_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.007695239935415004\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<1668x26287 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 337411 stored elements in Compressed Sparse Row format>"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# This will be a sparse matrix because most of the words are not used in many texts\n",
        "\n",
        "print((x_train != 0).sum()/np.prod(x_train.shape)) # This is the proportion of non-zero elements (0.8%)\n",
        "x_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train score =  0.9922062350119905\n",
            "Test score =  0.9712746858168761\n"
          ]
        }
      ],
      "source": [
        "# Now let's classify a bit\n",
        "\n",
        "model = MultinomialNB()\n",
        "\n",
        "model.fit(x_train, y_train)\n",
        "print(\"Train score = \", model.score(x_train, y_train))\n",
        "print(\"Test score = \", model.score(x_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And the scores are pretty good but probably we can improve it a bit. Remove stopwords, lemmatize, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train score =  0.9928057553956835\n",
            "Test score =  0.9766606822262118\n",
            "Size of x_train is:  (1668, 25995)\n"
          ]
        }
      ],
      "source": [
        "# With stopwords I can improve the accuracy a bit\n",
        "\n",
        "vectorizer = CountVectorizer(stop_words = \"english\")\n",
        "x_train = vectorizer.fit_transform(inputs_train)\n",
        "x_test = vectorizer.transform(inputs_test)\n",
        "model = MultinomialNB()\n",
        "model.fit(x_train, y_train)\n",
        "print(\"Train score = \", model.score(x_train, y_train))\n",
        "print(\"Test score = \", model.score(x_test, y_test))\n",
        "print(\"Size of x_train is: \", x_train.shape) # The shape will be different if we perform different stemming/lemmatization or anything like that"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_wordnet_pos(treebank_tag):\n",
        "    \"\"\"NLTK and the lemmatizer are not compatible off the shelf, convert the tags to avoid typing every time\"\"\"\n",
        "\n",
        "    if treebank_tag.startswith(\"J\"):\n",
        "        return wordnet.ADJ\n",
        "\n",
        "    if treebank_tag.startswith(\"V\"):\n",
        "        return wordnet.VERB\n",
        "\n",
        "    if treebank_tag.startswith(\"N\"):\n",
        "        return wordnet.NOUN\n",
        "\n",
        "    if treebank_tag.startswith(\"R\"):\n",
        "        return wordnet.ADV\n",
        "\n",
        "    else:\n",
        "        return wordnet.NOUN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a class and call it as if it was a function. I want to lemmatize and tokenize automatically in one step\n",
        "\n",
        "class LemmaTokenizer:\n",
        "    def __init__(self):\n",
        "        self.wnl = WordNetLemmatizer()\n",
        "    def __call__(self, doc):\n",
        "        tokens = word_tokenize(doc)\n",
        "        words_and_tags = nltk.pos_tag(tokens)\n",
        "        return [self.wnl.lemmatize(word, pos = get_wordnet_pos(tag)) for word, tag in words_and_tags]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train score =  0.9922062350119905\n",
            "Test score =  0.9676840215439856\n",
            "Size of x_train is:  (1668, 26000)\n"
          ]
        }
      ],
      "source": [
        "# With lemmatization. It takes significantly longer to run (Lemmatization) but the accuracy doesn't improve\n",
        "\n",
        "vectorizer = CountVectorizer(tokenizer = LemmaTokenizer())\n",
        "x_train = vectorizer.fit_transform(inputs_train)\n",
        "x_test = vectorizer.transform(inputs_test)\n",
        "model = MultinomialNB()\n",
        "model.fit(x_train, y_train)\n",
        "print(\"Train score = \", model.score(x_train, y_train))\n",
        "print(\"Test score = \", model.score(x_test, y_test))\n",
        "print(\"Size of x_train is: \", x_train.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "class StemTokenizer:\n",
        "    def __init__(self):\n",
        "        self.porter = PorterStemmer()\n",
        "    def __call__(self, doc):\n",
        "        tokens = word_tokenize(doc)\n",
        "        return [self.porter.stem(t) for t in tokens]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train score =  0.9892086330935251\n",
            "Test score =  0.9694793536804309\n",
            "Size of x_train is:  (1668, 22828)\n"
          ]
        }
      ],
      "source": [
        "# With Stemming. It takes a bit longer to run (Stemming) but the accuracy doesn't improve\n",
        "\n",
        "vectorizer = CountVectorizer(tokenizer = StemTokenizer())\n",
        "x_train = vectorizer.fit_transform(inputs_train)\n",
        "x_test = vectorizer.transform(inputs_test)\n",
        "model = MultinomialNB()\n",
        "model.fit(x_train, y_train)\n",
        "print(\"Train score = \", model.score(x_train, y_train))\n",
        "print(\"Test score = \", model.score(x_test, y_test))\n",
        "print(\"Size of x_train is: \", x_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Now try a stupid tokenizer\n",
        "\n",
        "def simple_tokenizer(s):\n",
        "    return s.split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train score =  0.9952038369304557\n",
            "Test score =  0.9712746858168761\n",
            "Size of x_train is:  (1668, 52144)\n"
          ]
        }
      ],
      "source": [
        "# Train is a bit better but the test score is the same. This is a reasonable choice\n",
        "\n",
        "vectorizer = CountVectorizer(tokenizer = simple_tokenizer)\n",
        "x_train = vectorizer.fit_transform(inputs_train)\n",
        "x_test = vectorizer.transform(inputs_test)\n",
        "model = MultinomialNB()\n",
        "model.fit(x_train, y_train)\n",
        "print(\"Train score = \", model.score(x_train, y_train))\n",
        "print(\"Test score = \", model.score(x_test, y_test))\n",
        "print(\"Size of x_train is: \", x_train.shape) # This is huge because we kept the full words"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
