{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text sumarization",
      "provenance": [],
      "authorship_tag": "ABX9TyOoXQLpMs9yxNy61M7NMsca",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DrAlexSanz/nlpv2-course/blob/master/Text_sumarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is extractive summarization, meaning that I score each sentence in the document and then I take the n best phrases as a summary. In this case I don't need a training/test set, the document that I need to summarize is my only data.\n",
        "\n",
        "The alternative is generative summarization. The model reads the document and generates a summary that is not necessarily made of sentences in the document. Just generating the text is a whole new problem and that is when I would use seq2seq models."
      ],
      "metadata": {
        "id": "EkIyGFIgc9aV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "zah84cTG70p-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import textwrap\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"stopwords\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2n5DiEMedvqH",
        "outputId": "55220c54-8794-43c5-8d7f-56df4bdd01a2"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the data\n",
        "\n",
        "!wget https://lazyprogrammer.me/course_files/nlp/bbc_text_cls.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nMijnrt8VLl",
        "outputId": "399be8b4-3768-48ac-9835-785b42ca722e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-08-05 15:18:51--  https://lazyprogrammer.me/course_files/nlp/bbc_text_cls.csv\n",
            "Resolving lazyprogrammer.me (lazyprogrammer.me)... 104.21.23.210, 172.67.213.166, 2606:4700:3031::6815:17d2, ...\n",
            "Connecting to lazyprogrammer.me (lazyprogrammer.me)|104.21.23.210|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5085081 (4.8M) [text/csv]\n",
            "Saving to: ‘bbc_text_cls.csv.1’\n",
            "\n",
            "bbc_text_cls.csv.1  100%[===================>]   4.85M  5.40MB/s    in 0.9s    \n",
            "\n",
            "2022-08-05 15:18:52 (5.40 MB/s) - ‘bbc_text_cls.csv.1’ saved [5085081/5085081]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"bbc_text_cls.csv\")"
      ],
      "metadata": {
        "id": "Tc0-zXa28gP8"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "RzHb6InY8oiV",
        "outputId": "88f7c6cf-f07b-4e4e-b417-9bbc80f5ad96"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text    labels\n",
              "0  Ad sales boost Time Warner profit\\n\\nQuarterly...  business\n",
              "1  Dollar gains on Greenspan speech\\n\\nThe dollar...  business\n",
              "2  Yukos unit buyer faces loan claim\\n\\nThe owner...  business\n",
              "3  High fuel prices hit BA's profits\\n\\nBritish A...  business\n",
              "4  Pernod takeover talk lifts Domecq\\n\\nShares in...  business"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7f002672-95d3-4888-aab6-50ef63b02f0c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>High fuel prices hit BA's profits\\n\\nBritish A...</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Pernod takeover talk lifts Domecq\\n\\nShares in...</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7f002672-95d3-4888-aab6-50ef63b02f0c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7f002672-95d3-4888-aab6-50ef63b02f0c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7f002672-95d3-4888-aab6-50ef63b02f0c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# My dataset is just one article\n",
        "doc = df[df[\"labels\"] == \"business\"][\"text\"].sample(random_state = 42)"
      ],
      "metadata": {
        "id": "KVbBViyU8wKO"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def wrap_text(x):\n",
        "    return textwrap.fill(x, replace_whitespace = False, fix_sentence_endings = True)"
      ],
      "metadata": {
        "id": "sQY-x1Oo9AjE"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's have a look at what I want to summarize. The title is included and it could just be a good summary or a baseline\n",
        "print(wrap_text(doc.iloc[0]))"
      ],
      "metadata": {
        "id": "PJZO_SuLi-tE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c069c91-7e5c-4532-bdaa-15101d495566"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Christmas sales worst since 1981\n",
            "\n",
            "UK retail sales fell in December,\n",
            "failing to meet expectations and making it by some counts the worst\n",
            "Christmas since 1981.\n",
            "\n",
            "Retail sales dropped by 1% on the month in\n",
            "December, after a 0.6% rise in November, the Office for National\n",
            "Statistics (ONS) said.  The ONS revised the annual 2004 rate of growth\n",
            "down from the 5.9% estimated in November to 3.2%. A number of\n",
            "retailers have already reported poor figures for December.  Clothing\n",
            "retailers and non-specialist stores were the worst hit with only\n",
            "internet retailers showing any significant growth, according to the\n",
            "ONS.\n",
            "\n",
            "The last time retailers endured a tougher Christmas was 23 years\n",
            "previously, when sales plunged 1.7%.\n",
            "\n",
            "The ONS echoed an earlier\n",
            "caution from Bank of England governor Mervyn King not to read too much\n",
            "into the poor December figures.  Some analysts put a positive gloss on\n",
            "the figures, pointing out that the non-seasonally-adjusted figures\n",
            "showed a performance comparable with 2003. The November-December jump\n",
            "last year was roughly comparable with recent averages, although some\n",
            "way below the serious booms seen in the 1990s.  And figures for retail\n",
            "volume outperformed measures of actual spending, an indication that\n",
            "consumers are looking for bargains, and retailers are cutting their\n",
            "prices.\n",
            "\n",
            "However, reports from some High Street retailers highlight\n",
            "the weakness of the sector.  Morrisons, Woolworths, House of Fraser,\n",
            "Marks & Spencer and Big Food all said that the festive period was\n",
            "disappointing.\n",
            "\n",
            "And a British Retail Consortium survey found that\n",
            "Christmas 2004 was the worst for 10 years.  Yet, other retailers -\n",
            "including HMV, Monsoon, Jessops, Body Shop and Tesco - reported that\n",
            "festive sales were well up on last year.  Investec chief economist\n",
            "Philip Shaw said he did not expect the poor retail figures to have any\n",
            "immediate effect on interest rates.  \"The retail sales figures are\n",
            "very weak, but as Bank of England governor Mervyn King indicated last\n",
            "night, you don't really get an accurate impression of Christmas\n",
            "trading until about Easter,\" said Mr Shaw.  \"Our view is the Bank of\n",
            "England will keep its powder dry and wait to see the big picture.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tokenize document into sentences\n",
        "\n",
        "sents = nltk.sent_tokenize(doc.iloc[0].split(\"\\n\", 1)[1]) # Remove the title and split. This will produce a list [title, text] and I take the text"
      ],
      "metadata": {
        "id": "HrDs8zIhYHWR"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWAZqDrfhd1d",
        "outputId": "33f44987-ceb9-47b8-bc89-e4ae64fc1792"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\nUK retail sales fell in December, failing to meet expectations and making it by some counts the worst Christmas since 1981.',\n",
              " 'Retail sales dropped by 1% on the month in December, after a 0.6% rise in November, the Office for National Statistics (ONS) said.',\n",
              " 'The ONS revised the annual 2004 rate of growth down from the 5.9% estimated in November to 3.2%.',\n",
              " 'A number of retailers have already reported poor figures for December.',\n",
              " 'Clothing retailers and non-specialist stores were the worst hit with only internet retailers showing any significant growth, according to the ONS.',\n",
              " 'The last time retailers endured a tougher Christmas was 23 years previously, when sales plunged 1.7%.',\n",
              " 'The ONS echoed an earlier caution from Bank of England governor Mervyn King not to read too much into the poor December figures.',\n",
              " 'Some analysts put a positive gloss on the figures, pointing out that the non-seasonally-adjusted figures showed a performance comparable with 2003.',\n",
              " 'The November-December jump last year was roughly comparable with recent averages, although some way below the serious booms seen in the 1990s.',\n",
              " 'And figures for retail volume outperformed measures of actual spending, an indication that consumers are looking for bargains, and retailers are cutting their prices.',\n",
              " 'However, reports from some High Street retailers highlight the weakness of the sector.',\n",
              " 'Morrisons, Woolworths, House of Fraser, Marks & Spencer and Big Food all said that the festive period was disappointing.',\n",
              " 'And a British Retail Consortium survey found that Christmas 2004 was the worst for 10 years.',\n",
              " 'Yet, other retailers - including HMV, Monsoon, Jessops, Body Shop and Tesco - reported that festive sales were well up on last year.',\n",
              " 'Investec chief economist Philip Shaw said he did not expect the poor retail figures to have any immediate effect on interest rates.',\n",
              " '\"The retail sales figures are very weak, but as Bank of England governor Mervyn King indicated last night, you don\\'t really get an accurate impression of Christmas trading until about Easter,\" said Mr Shaw.',\n",
              " '\"Our view is the Bank of England will keep its powder dry and wait to see the big picture.\"']"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "featurizer = TfidfVectorizer(stop_words = stopwords.words(\"english\"), norm = \"l1\")"
      ],
      "metadata": {
        "id": "q-Qu8t-wjg_i"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = featurizer.fit_transform(sents)\n",
        "x\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3nlDzNuj_8i",
        "outputId": "05d16545-c71a-4830-b80f-ec753b2131d1"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<17x154 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 212 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sentence_score(tfidf_row):\n",
        "    \"\"\"given a row of the TfIdf matrix I calculate the mean (removing 0s). Remember that a row is a sentence\"\"\"\n",
        "    row = tfidf_row[tfidf_row != 0]\n",
        "\n",
        "    return row.mean()"
      ],
      "metadata": {
        "id": "Zmg-mMmDlK6a"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# and now get the scores for each row. I can probably find a better way to do it with numpy but the where and the mask of np.mean() is confusing\n",
        "\n",
        "scores = np.zeros(len(sents))\n",
        "\n",
        "for i in range(len(sents)):\n",
        "    row_score = get_sentence_score(x[i, :])\n",
        "    scores[i] = row_score"
      ],
      "metadata": {
        "id": "-0pbPaBhil1D"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort the scores, and take the top n sentences.\n",
        "\n",
        "# Alternatively:\n",
        "# top N words or characters (for tags)\n",
        "# top n% of sentences or words\n",
        "# Use a threshold and take all the sentences above\n",
        "# Use a threshold and multiply the averages by a weight factor\n",
        "\n",
        "sort_idx = np.argsort(-scores) # It's sorting ASC by default\n",
        "\n",
        "# Without sorting\n",
        "\n",
        "ind = np.argpartition(scores, -5)[-5:]\n",
        "ind"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlYLFeFXg4k0",
        "outputId": "b0cf1a35-de91-487a-c2cc-cc349ca6f57f"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([16, 12,  3,  2, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The result is not too bad! And I don't need to print the scores but why not?\n",
        "# I don't need to sort by score, maybe I don't want to scramble the phrases\n",
        "\n",
        "print(\"Here is the summary:\")\n",
        "for i in sort_idx[:5]:\n",
        "    print(wrap_text(\"%.2f: %s\" % (scores[i], sents[i])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQR-xV-6hX98",
        "outputId": "fff0c370-2c98-45cc-932b-89a7b750bc41"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here is the summary:\n",
            "0.14: A number of retailers have already reported poor figures for\n",
            "December.\n",
            "0.13: However, reports from some High Street retailers highlight the\n",
            "weakness of the sector.\n",
            "0.12: The ONS revised the annual 2004 rate of growth down from the\n",
            "5.9% estimated in November to 3.2%.\n",
            "0.10: \"Our view is the Bank of England will keep its powder dry and\n",
            "wait to see the big picture.\"\n",
            "0.10: And a British Retail Consortium survey found that Christmas 2004\n",
            "was the worst for 10 years.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Without sorting, in case it's a story or something like that\n",
        "for i in ind:\n",
        "    print(wrap_text(\"%.2f: %s\" % (scores[i], sents[i])))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ib1mFBI8mZ3R",
        "outputId": "2b311ecf-8cdf-4fc4-dc95-c31dab8f12bc"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.10: \"Our view is the Bank of England will keep its powder dry and\n",
            "wait to see the big picture.\"\n",
            "0.10: And a British Retail Consortium survey found that Christmas 2004\n",
            "was the worst for 10 years.\n",
            "0.14: A number of retailers have already reported poor figures for\n",
            "December.\n",
            "0.12: The ONS revised the annual 2004 rate of growth down from the\n",
            "5.9% estimated in November to 3.2%.\n",
            "0.13: However, reports from some High Street retailers highlight the\n",
            "weakness of the sector.\n"
          ]
        }
      ]
    }
  ]
}